{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3 â€” Pre-Processing & First Model \n",
    "MLB Game Prediction: Data Ingestion, Preprocessing, and Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion and Assembly \n",
    "\n",
    "### We fetch live game data and team statistics, merging them into a single DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching game data...\n",
      "Game data shape: (2430, 15)\n",
      "Fetching team stats...\n",
      "Final merged DataFrame 'g' created. Shape: (2430, 29)\n",
      "Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pybaseball import team_batting, team_pitching, cache\n",
    "\n",
    "# --- Configuration and Setup ---\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=r\".*pybaseball.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\"Could not infer format.*\")\n",
    "\n",
    "cache.enable()\n",
    "\n",
    "SEASONS = [2023]\n",
    "TEAMS = ['ARI','ATL','BAL','BOS','CHC','CHW','CIN','CLE','COL','DET','HOU','KCR','LAA','LAD','MIA','MIL','MIN','NYM','NYY','OAK','PHI','PIT','SDP','SEA','SFG','STL','TBR','TEX','TOR','WSN']\n",
    "\n",
    "# --- Data Loading Functions (CORRECTED) ---\n",
    "TEAM_LEAGUE = {\n",
    "    'ARI':'NL','ATL':'NL','BAL':'AL','BOS':'AL','CHC':'NL','CHW':'AL','CIN':'NL','CLE':'AL',\n",
    "    'COL':'NL','DET':'AL','HOU':'AL','KCR':'AL','LAA':'AL','LAD':'NL','MIA':'NL','MIL':'NL',\n",
    "    'MIN':'AL','NYM':'NL','NYY':'AL','OAK':'AL','PHI':'NL','PIT':'NL','SDP':'NL','SEA':'AL',\n",
    "    'SFG':'NL','STL':'NL','TBR':'AL','TEX':'AL','TOR':'AL','WSN':'NL'\n",
    "}\n",
    "STATS_ABBR = { 'ARI':'ARI','ATL':'ATL','BAL':'BAL','BOS':'BOS','CHC':'CHC','CHW':'CWS','CIN':'CIN','CLE':'CLE', 'COL':'COL','DET':'DET','HOU':'HOU','KCR':'KC','LAA':'LAA','LAD':'LAD','MIA':'MIA','MIL':'MIL', 'MIN':'MIN','NYM':'NYM','NYY':'NYY','OAK':'OAK','PHI':'PHI','PIT':'PIT','SDP':'SD','SEA':'SEA', 'SFG':'SF','STL':'STL','TBR':'TB','TEX':'TEX','TOR':'TOR','WSN':'WSH' }\n",
    "INVERSE_STATS_ABBR = {v: k for k, v in STATS_ABBR.items()}\n",
    "STATIC_ABBR_TO_ID = {\n",
    "    'ARI':109, 'ATL':144, 'BAL':110, 'BOS':111, 'CHC':112, 'CWS':145, 'CIN':113, 'CLE':114,\n",
    "    'COL':115, 'DET':116, 'HOU':117, 'KC':118, 'LAA':108, 'LAD':119, 'MIA':146, 'MIL':158,\n",
    "    'MIN':142, 'NYM':121, 'NYY':147, 'OAK':133, 'PHI':143, 'PIT':134, 'SD':135, 'SEA':136,\n",
    "    'SF':137, 'STL':138, 'TB':139, 'TEX':140, 'TOR':141, 'WSH':120\n",
    "}\n",
    "ABBR_TO_NAME = {\n",
    "    'ARI':'Arizona Diamondbacks','ATL':'Atlanta Braves','BAL':'Baltimore Orioles','BOS':'Boston Red Sox',\n",
    "    'CHC':'Chicago Cubs','CHW':'Chicago White Sox','CIN':'Cincinnati Reds','CLE':'Cleveland Guardians',\n",
    "    'COL':'Colorado Rockies','DET':'Detroit Tigers','HOU':'Houston Astros','KCR':'Kansas City Royals',\n",
    "    'LAA':'Los Angeles Angels','LAD':'Los Angeles Dodgers','MIA':'Miami Marlins','MIL':'Milwaukee Brewers',\n",
    "    'MIN':'Minnesota Twins','NYM':'New York Mets','NYY':'New York Yankees','OAK':'Oakland Athletics',\n",
    "    'PHI':'Philadelphia Phillies','PIT':'Pittsburgh Pirates','SDP':'San Diego Padres','SEA':'Seattle Mariners',\n",
    "    'SFG':'San Francisco Giants','STL':'St. Louis Cardinals','TBR':'Tampa Bay Rays','TEX':'Texas Rangers',\n",
    "    'TOR':'Toronto Blue Jays','WSN':'Washington Nationals'\n",
    "}\n",
    "NAME_TO_ABBR = {v: k for k, v in ABBR_TO_NAME.items()}\n",
    "ALIASES = {'WSH':'WSN','TB':'TBR','SD':'SDP','KC':'KCR','CWS':'CHW','SF':'SFG','AZ':'ARI'}\n",
    "\n",
    "_ID_BY_ABBR = {}\n",
    "_ABBR_BY_ID = {}\n",
    "\n",
    "def _init_team_maps(season: int):\n",
    "    global _ID_BY_ABBR, _ABBR_BY_ID\n",
    "    if _ID_BY_ABBR: return\n",
    "    api_abbr_to_id = {}\n",
    "    for params in ({\"sportId\": 1, \"season\": season}, {\"sportId\": 1}):\n",
    "        try:\n",
    "            r = requests.get(\"https://statsapi.mlb.com/api/v1/teams\", params=params, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            teams = r.json().get(\"teams\", [])\n",
    "            api_abbr_to_id = {t.get(\"abbreviation\"): t.get(\"id\") for t in teams if t.get(\"abbreviation\") and t.get(\"id\")}\n",
    "            if api_abbr_to_id: break\n",
    "        except Exception: continue\n",
    "    merged = dict(STATIC_ABBR_TO_ID)\n",
    "    merged.update(api_abbr_to_id)\n",
    "    _ABBR_BY_ID = {tid: abbr for abbr, tid in merged.items()}\n",
    "    _ID_BY_ABBR = {mine: merged[api] for mine, api in STATS_ABBR.items()}\n",
    "\n",
    "def _fetch_sched(season, team):\n",
    "    _init_team_maps(season)\n",
    "    tid = _ID_BY_ABBR.get(team)\n",
    "    if tid is None: raise KeyError(team)\n",
    "    r = requests.get(\"https://statsapi.mlb.com/api/v1/schedule\", params={\"sportId\": 1, \"teamId\": tid, \"startDate\": f\"03/01/{season}\", \"endDate\": f\"12/31/{season}\", \"gameType\": \"R\"}, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    games = []\n",
    "    for d in data.get(\"dates\", []):\n",
    "        for g in d.get(\"games\", []):\n",
    "            tm = g.get(\"teams\", {})\n",
    "            home, away = tm.get(\"home\", {}), tm.get(\"away\", {})\n",
    "            # FIX: Added \"day_night\" to the fields being fetched\n",
    "            games.append({\n",
    "                \"game_pk\": g.get(\"gamePk\"), \"game_date\": d.get(\"date\"),\n",
    "                \"home_id\": (home.get(\"team\") or {}).get(\"id\"), \"away_id\": (away.get(\"team\") or {}).get(\"id\"),\n",
    "                \"home_score\": home.get(\"score\"), \"away_score\": away.get(\"score\"),\n",
    "                \"game_num\": g.get(\"gameNumber\"), \"day_night\": g.get(\"dayNight\")\n",
    "            })\n",
    "    df = pd.DataFrame(games)\n",
    "    if df.empty: return df\n",
    "    is_home = df[\"home_id\"].eq(tid)\n",
    "    opp = df[\"away_id\"].map(_ABBR_BY_ID).where(is_home, df[\"home_id\"].map(_ABBR_BY_ID)).astype(object)\n",
    "    idx = df.index\n",
    "    out = pd.DataFrame(index=idx)\n",
    "    out[\"Tm\"] = pd.Series(team, index=idx, dtype=object)\n",
    "    out[\"Opp\"] = opp\n",
    "    out[\"Home_Away\"] = pd.Series(np.where(is_home, \"\", \"@\"), index=idx, dtype=object)\n",
    "    out[\"Date\"] = pd.to_datetime(df[\"game_date\"], errors=\"coerce\").dt.strftime(\"%b %d\")\n",
    "    out[\"R\"] = pd.to_numeric(df[\"home_score\"].where(is_home, df[\"away_score\"]), errors=\"coerce\")\n",
    "    out[\"RA\"] = pd.to_numeric(df[\"away_score\"].where(is_home, df[\"home_score\"]), errors=\"coerce\")\n",
    "    out[\"game_id\"] = df[\"game_pk\"]\n",
    "    # FIX: Added \"D/N\" (Day/Night) column to the output\n",
    "    out[\"D/N\"] = df[\"day_night\"]\n",
    "    return out[[\"Tm\", \"Opp\", \"Date\", \"R\", \"RA\", \"Home_Away\", \"D/N\", \"game_id\"]]\n",
    "\n",
    "def _parse_bbref_date(raw_series: pd.Series, season: int) -> pd.Series:\n",
    "    s = raw_series.astype(str).str.replace(r\"\\\\(.*?\\\\)\", \"\", regex=True).str.replace(r\"^[A-Za-z]{3,9},\\\\s*\", \"\", regex=True).str.strip() + f\" {season}\"\n",
    "    return pd.to_datetime(s, format=\"%b %d %Y\", errors=\"coerce\")\n",
    "\n",
    "def _parse_day_night(x):\n",
    "    x_str = str(x).strip().upper()\n",
    "    if x_str in (\"D\", \"DAY\"): return \"Day\"\n",
    "    if x_str in (\"N\", \"NIGHT\"): return \"Night\"\n",
    "    return None\n",
    "\n",
    "def load_games_for_season(season: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for tm in TEAMS:\n",
    "        df = _fetch_sched(season, tm)\n",
    "        if df is None or df.empty: continue\n",
    "        df = df[~df[\"Home_Away\"].astype(str).str.contains(\"@\")]\n",
    "        df = df[df[\"R\"].notna() & df[\"RA\"].notna()].copy()\n",
    "        df[\"date\"] = _parse_bbref_date(df[\"Date\"], season)\n",
    "        df = df.rename(columns={\"Tm\":\"home_team\",\"Opp\":\"away_team\",\"R\":\"home_runs\",\"RA\":\"away_runs\"})\n",
    "        df[\"away_team\"] = df[\"away_team\"].map(INVERSE_STATS_ABBR).fillna(df[\"away_team\"])\n",
    "        df[\"home_win\"] = (df[\"home_runs\"] > df[\"away_runs\"]).astype(int)\n",
    "        df[\"season\"] = season\n",
    "        # FIX: Process the 'D/N' column into 'day_night'\n",
    "        df[\"day_night\"] = df[\"D/N\"].apply(_parse_day_night)\n",
    "        df[\"run_diff\"] = df[\"home_runs\"] - df[\"away_runs\"]\n",
    "        df[\"month\"] = df[\"date\"].dt.month\n",
    "        df[\"weekday\"] = df[\"date\"].dt.day_name()\n",
    "        df[\"home_league\"] = df[\"home_team\"].map(TEAM_LEAGUE)\n",
    "        df[\"away_league\"] = df[\"away_team\"].map(TEAM_LEAGUE)\n",
    "        df[\"is_interleague\"] = (df[\"home_league\"] != df[\"away_league\"]).astype(int)\n",
    "        # FIX: Added 'day_night' to the columns to keep\n",
    "        keep_cols = [\"season\",\"date\",\"home_team\",\"away_team\",\"home_runs\",\"away_runs\",\"home_win\",\"run_diff\",\"month\",\"weekday\",\"day_night\",\"home_league\",\"away_league\",\"is_interleague\",\"game_id\"]\n",
    "        rows.append(df[[c for c in keep_cols if c in df.columns]])\n",
    "    out = pd.concat(rows, ignore_index=True).dropna(subset=[\"date\"])\n",
    "    out = out.drop_duplicates(subset=[\"game_id\"])\n",
    "    return out.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def normalize_team_key(df: pd.DataFrame, team_col: str = \"Team\") -> pd.Series:\n",
    "    vals = df[team_col].astype(str).str.strip().str.replace(r\"\\\\s*\\\\(.*\\\\)$\", \"\", regex=True)\n",
    "    if vals.isin(set(ABBR_TO_NAME.keys())).mean() >= 0.9: return vals.replace(ALIASES)\n",
    "    return vals.map(NAME_TO_ABBR)\n",
    "\n",
    "def team_batting_minimal(season: int) -> pd.DataFrame:\n",
    "    tb = team_batting(season).copy()\n",
    "    tb.columns = tb.columns.str.strip()\n",
    "    if \"BA\" not in tb.columns and \"AVG\" in tb.columns:\n",
    "        tb = tb.rename(columns={\"AVG\": \"BA\"})\n",
    "    if \"OPS\" not in tb.columns and {\"OBP\",\"SLG\"}.issubset(tb.columns): tb[\"OPS\"] = tb[\"OBP\"] + tb[\"SLG\"]\n",
    "    keep = [c for c in [\"Team\",\"BA\",\"OBP\",\"SLG\",\"OPS\",\"R\"] if c in tb.columns]\n",
    "    tb = tb[keep].rename(columns={\"R\":\"season_runs\"})\n",
    "    tb[\"team\"] = normalize_team_key(tb, \"Team\")\n",
    "    return tb[[\"team\",\"BA\",\"OBP\",\"SLG\",\"OPS\",\"season_runs\"]]\n",
    "\n",
    "def team_pitching_minimal(season: int) -> pd.DataFrame:\n",
    "    tp = team_pitching(season).copy()\n",
    "    tp.columns = tp.columns.str.strip()\n",
    "    keep = [c for c in [\"Team\",\"ERA\",\"WHIP\"] if c in tp.columns]\n",
    "    tp = tp[keep]\n",
    "    tp[\"team\"] = normalize_team_key(tp, \"Team\")\n",
    "    return tp[[\"team\",\"ERA\",\"WHIP\"]]\n",
    "\n",
    "# --- Execute Data Loading ---\n",
    "print(\"Fetching game data...\")\n",
    "games = pd.concat([load_games_for_season(y) for y in SEASONS], ignore_index=True)\n",
    "print(\"Game data shape:\", games.shape)\n",
    "\n",
    "print(\"Fetching team stats...\")\n",
    "bat = pd.concat([team_batting_minimal(y) for y in SEASONS], ignore_index=True)\n",
    "pit = pd.concat([team_pitching_minimal(y) for y in SEASONS], ignore_index=True)\n",
    "team_stats = bat.merge(pit, on=\"team\", how=\"inner\")\n",
    "\n",
    "g = games.merge(team_stats.add_prefix(\"home_\"), left_on=\"home_team\", right_on=\"home_team\", how=\"left\")\n",
    "g = g.merge(team_stats.add_prefix(\"away_\"), left_on=\"away_team\", right_on=\"away_team\", how=\"left\")\n",
    "print(\"Final merged DataFrame 'g' created. Shape:\", g.shape)\n",
    "print(\"Data loading complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Modeling\n",
    "### Clean data, add matchup features, split into train/val/test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  Train: (1689, 81)  Val: (423, 81)  Test: (528, 81)\n",
      "  Class balance: {np.int64(0): np.int64(809), np.int64(1): np.int64(880)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "df = g.copy()  # replace 'g' if your variable name differs\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# -- 1) Drop outcome-leakers if present\n",
    "leakers = [c for c in ['home_runs','away_runs','run_diff','home_score','away_score'] if c in df.columns]\n",
    "df = df.drop(columns=leakers, errors='ignore')\n",
    "\n",
    "# -- 2) Feature expansion: diffs, ratios (safe divide), ERA-advantage\n",
    "def _safe_div(a, b):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        r = np.divide(a, b, where=(b!=0))\n",
    "        r[~np.isfinite(r)] = 0.0\n",
    "    return r\n",
    "\n",
    "for sfx in ['OPS','ERA','WHIP','BA']:\n",
    "    h, a = f'home_{sfx}', f'away_{sfx}'\n",
    "    if h in df.columns and a in df.columns:\n",
    "        df[f'delta_{sfx.lower()}'] = df[h] - df[a]\n",
    "        df[f'ratio_{sfx.lower()}'] = _safe_div(df[h].to_numpy(), df[a].to_numpy())\n",
    "        if sfx == 'ERA':\n",
    "            df['adv_era'] = df[a] - df[h]  # positive means home has better (lower) ERA\n",
    "\n",
    "def add_rolling_form(df, date_col, ks=(10, 7, 15)):\n",
    "    \"\"\"\n",
    "    Adds home_last{k}_win_pct and away_last{k}_win_pct for each k.\n",
    "    Leakage-safe via shift(1): only prior games count.\n",
    "    \"\"\"\n",
    "    req = {'home_team', 'away_team', 'home_win', date_col}\n",
    "    if not req.issubset(df.columns):\n",
    "        return df  # missing required columns; skip gracefully\n",
    "\n",
    "    out = df.copy()\n",
    "    out[date_col] = pd.to_datetime(out[date_col], errors='coerce')\n",
    "\n",
    "    # Long view: one row per (team, game)\n",
    "    home = out[[date_col, 'home_team', 'home_win']].rename(\n",
    "        columns={'home_team': 'team', 'home_win': 'team_win'}\n",
    "    )\n",
    "    home['is_home'] = 1\n",
    "\n",
    "    away = out[[date_col, 'away_team', 'home_win']].rename(\n",
    "        columns={'away_team': 'team'}\n",
    "    )\n",
    "    away['team_win'] = 1 - away['home_win']  # away wins when home loses\n",
    "    away['is_home'] = 0\n",
    "\n",
    "    long = pd.concat([home, away], ignore_index=True)\n",
    "    long = long.sort_values(['team', date_col])\n",
    "\n",
    "    # Rolling win% for prior k games\n",
    "    for k in ks:\n",
    "        long[f'last{k}_win_pct'] = (\n",
    "            long.groupby('team', group_keys=False)['team_win']\n",
    "                .apply(lambda s: s.shift(1).rolling(window=k, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "    # Split back to home/away and merge to original\n",
    "    home_cols = [date_col, 'team'] + [f'last{k}_win_pct' for k in ks]\n",
    "    away_cols = home_cols.copy()\n",
    "\n",
    "    home_form = (long[long['is_home'] == 1][home_cols]\n",
    "                 .rename(columns={'team': 'home_team', **{f'last{k}_win_pct': f'home_last{k}_win_pct' for k in ks}}))\n",
    "    away_form = (long[long['is_home'] == 0][away_cols]\n",
    "                 .rename(columns={'team': 'away_team', **{f'last{k}_win_pct': f'away_last{k}_win_pct' for k in ks}}))\n",
    "\n",
    "    out = out.merge(home_form, on=[date_col, 'home_team'], how='left')\n",
    "    out = out.merge(away_form, on=[date_col, 'away_team'], how='left')\n",
    "\n",
    "    # Leave early-season NaNs; your imputer in the pipeline will handle them\n",
    "    return out\n",
    "\n",
    "date_col = next((c for c in ['date','game_date'] if c in df.columns), None)\n",
    "\n",
    "if date_col:\n",
    "    df = add_rolling_form(df, date_col=date_col, ks=(10, 7, 15))\n",
    "\n",
    "# -- 3) Column groups\n",
    "target = 'home_win'\n",
    "assert target in df.columns, \"home_win target missing.\"\n",
    "id_cols = [c for c in ['season','date','game_id'] if c in df.columns]\n",
    "cat_cols = [c for c in ['day_night','weekday','home_league','away_league','is_interleague','is_doubleheader','venue'] if c in df.columns]\n",
    "bool_cols = [c for c in df.columns if pd.api.types.is_bool_dtype(df[c])]\n",
    "num_cols = [c for c in df.columns\n",
    "            if c not in ([target] + id_cols + cat_cols + bool_cols)\n",
    "            and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "# -- Tiny degree-2 interactions on high-signal features\n",
    "# -- Tiny degree-2 interactions on high-signal features (select only a few)\n",
    "poly_base = [c for c in df.columns if c.startswith(('delta_','ratio_','adv_'))][:8]\n",
    "\n",
    "# -- Preprocessor blocks\n",
    "num_cols_all = [c for c in df.columns\n",
    "                if c not in ([target] + id_cols + cat_cols + bool_cols)\n",
    "                and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "# Split numeric columns into those we want poly on vs the rest\n",
    "num_poly_cols = [c for c in num_cols_all if c in poly_base]\n",
    "num_rest_cols = [c for c in num_cols_all if c not in num_poly_cols]\n",
    "\n",
    "num_rest_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "num_poly_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),             # <-- impute first (fixes NaN issue)\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe  = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "bool_pipe = Pipeline([\n",
    "    ('to_float', FunctionTransformer(lambda X: X.astype('float64'))),\n",
    "    ('impute', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Build ColumnTransformer: poly only applied to num_poly_cols, rest scaled normally\n",
    "transformers = []\n",
    "if num_rest_cols: transformers.append(('num',      num_rest_pipe, num_rest_cols))\n",
    "if num_poly_cols: transformers.append(('num_poly', num_poly_pipe, num_poly_cols))\n",
    "if cat_cols:      transformers.append(('cat',      cat_pipe,      cat_cols))\n",
    "if bool_cols:     transformers.append(('bool',     bool_pipe,     bool_cols))\n",
    "\n",
    "pre = ColumnTransformer(transformers, remainder='drop', sparse_threshold=0.3)\n",
    "\n",
    "# -- Design matrix/labels (unchanged)\n",
    "X_raw = df.drop(columns=[target] + id_cols, errors='ignore').copy()\n",
    "y = df[target].astype(int).values\n",
    "def time_split(Xdf, y, date_series=None, train=0.64, val=0.16, test=0.20, random_state=42):\n",
    "    \"\"\"\n",
    "    If date_series is provided, sorts by time and slices (train, val, test).\n",
    "    Otherwise, uses stratified random splits that preserve class balance.\n",
    "    \"\"\"\n",
    "    assert abs(train + val + test - 1.0) < 1e-8, \"Splits must sum to 1.\"\n",
    "\n",
    "    if date_series is not None:\n",
    "        ds = pd.to_datetime(date_series, errors='coerce')\n",
    "        # Put NaT (if any) at the beginning so they land in train\n",
    "        order = np.argsort(ds.fillna(pd.Timestamp.min).values)\n",
    "        X_sorted = Xdf.iloc[order].reset_index(drop=True)\n",
    "        y_sorted = y[order]\n",
    "        n = len(X_sorted)\n",
    "        a = int(n * train)\n",
    "        b = int(n * (train + val))\n",
    "        return (\n",
    "            X_sorted.iloc[:a], X_sorted.iloc[a:b], X_sorted.iloc[b:],\n",
    "            y_sorted[:a],      y_sorted[a:b],      y_sorted[b:]\n",
    "        )\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        Xdf, y, test_size=test, random_state=random_state, stratify=y\n",
    "    )\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "        X_tr, y_tr, test_size=val/(1-test), random_state=random_state, stratify=y_tr\n",
    "    )\n",
    "    return X_tr, X_va, X_te, y_tr, y_va, y_te\n",
    "\n",
    "\n",
    "\n",
    "X_tr_raw, X_va_raw, X_te_raw, y_tr, y_va, y_te = time_split(\n",
    "    X_raw, y, date_series=df[date_col] if date_col else None\n",
    ")\n",
    "\n",
    "# -- Fit preprocessor on TRAIN only; transform VAL/TEST (no leakage)\n",
    "X_tr = pre.fit_transform(X_tr_raw)\n",
    "X_va = pre.transform(X_va_raw)\n",
    "X_te = pre.transform(X_te_raw)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  Train:\", X_tr.shape, \" Val:\", X_va.shape, \" Test:\", X_te.shape)\n",
    "print(\"  Class balance:\", dict(zip(*np.unique(y_tr, return_counts=True))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models & Metrics\n",
    "\n",
    "### Train Decision Tree, KNN, SVM (RBF), and Naive Bayes; compare splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>0.673179</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.535985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.591474</td>\n",
       "      <td>0.598109</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.608052</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.537879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.646536</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.539773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  train_acc   val_acc  test_acc\n",
       "2       SVM_RBF   0.673179  0.602837  0.535985\n",
       "3    NaiveBayes   0.591474  0.598109  0.545455\n",
       "0  DecisionTree   0.608052  0.595745  0.537879\n",
       "1           KNN   0.646536  0.567376  0.539773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen model based on Val Acc: SVM_RBF\n",
      "Val balanced_acc: 0.6020531400966183\n",
      "Val macro_f1: 0.6018555869302138\n",
      "Test balanced_acc: 0.5362848243889136\n",
      "Test macro_f1: 0.535969868173258\n",
      "\n",
      "Validation classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Away(0)       0.60      0.57      0.58       207\n",
      "     Home(1)       0.61      0.64      0.62       216\n",
      "\n",
      "    accuracy                           0.60       423\n",
      "   macro avg       0.60      0.60      0.60       423\n",
      "weighted avg       0.60      0.60      0.60       423\n",
      "\n",
      "Validation confusion matrix:\n",
      " [[117  90]\n",
      " [ 78 138]]\n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Away(0)       0.53      0.55      0.54       259\n",
      "     Home(1)       0.55      0.52      0.53       269\n",
      "\n",
      "    accuracy                           0.54       528\n",
      "   macro avg       0.54      0.54      0.54       528\n",
      "weighted avg       0.54      0.54      0.54       528\n",
      "\n",
      "Test confusion matrix:\n",
      " [[143 116]\n",
      " [129 140]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Some models need dense arrays (SVM/KNN/NB). Convert safely if sparse.\n",
    "def to_dense(X):\n",
    "    return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "\n",
    "X_tr_d = to_dense(X_tr)\n",
    "X_va_d = to_dense(X_va)\n",
    "X_te_d = to_dense(X_te)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, random_state=42),\n",
    "    \"KNN\":          KNeighborsClassifier(n_neighbors=15),\n",
    "    \"SVM_RBF\":      SVC(C=2.0, gamma='scale', probability=True, class_weight='balanced', random_state=42),\n",
    "    \"NaiveBayes\":   GaussianNB()\n",
    "}\n",
    "\n",
    "rows = []\n",
    "reports = {}\n",
    "for name, mdl in models.items():\n",
    "    Xtr = X_tr_d if name != \"DecisionTree\" else X_tr_d  # tree also fine with dense\n",
    "    Xva = X_va_d\n",
    "    Xte = X_te_d\n",
    "    mdl.fit(Xtr, y_tr)\n",
    "    yhat_tr = mdl.predict(Xtr)\n",
    "    yhat_va = mdl.predict(Xva)\n",
    "    yhat_te = mdl.predict(Xte)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"train_acc\": accuracy_score(y_tr, yhat_tr),\n",
    "        \"val_acc\":   accuracy_score(y_va, yhat_va),\n",
    "        \"test_acc\":  accuracy_score(y_te, yhat_te),\n",
    "    })\n",
    "\n",
    "    reports[name] = {\n",
    "        \"val_report\":  classification_report(y_va, yhat_va, target_names=['Away(0)','Home(1)']),\n",
    "        \"test_report\": classification_report(y_te, yhat_te, target_names=['Away(0)','Home(1)']),\n",
    "        \"val_cm\":      confusion_matrix(y_va, yhat_va),\n",
    "        \"test_cm\":     confusion_matrix(y_te, yhat_te)\n",
    "    }\n",
    "\n",
    "Xd_va = to_dense(X_va)\n",
    "Xd_te = to_dense(X_te)\n",
    "\n",
    "summary = pd.DataFrame(rows).sort_values(\"val_acc\", ascending=False)\n",
    "display(summary)\n",
    "best_name = summary.iloc[0][\"model\"]\n",
    "best_model = models[best_name]\n",
    "print(f\"\\nChosen model based on Val Acc: {best_name}\")\n",
    "print(\"Val balanced_acc:\", balanced_accuracy_score(y_va, best_model.predict(Xd_va)))\n",
    "print(\"Val macro_f1:\",     f1_score(y_va, best_model.predict(Xd_va), average='macro'))\n",
    "print(\"Test balanced_acc:\", balanced_accuracy_score(y_te, best_model.predict(Xd_te)))\n",
    "print(\"Test macro_f1:\",     f1_score(y_te, best_model.predict(Xd_te), average='macro'))\n",
    "print(\"\\nValidation classification report:\\n\", reports[best_name][\"val_report\"])\n",
    "print(\"Validation confusion matrix:\\n\", reports[best_name][\"val_cm\"])\n",
    "print(\"\\nTest classification report:\\n\", reports[best_name][\"test_report\"])\n",
    "print(\"Test confusion matrix:\\n\", reports[best_name][\"test_cm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597395</td>\n",
       "      <td>0.598109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.595027</td>\n",
       "      <td>0.598109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.608052</td>\n",
       "      <td>0.595745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.611012</td>\n",
       "      <td>0.593381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.593250</td>\n",
       "      <td>0.591017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.621078</td>\n",
       "      <td>0.581560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614565</td>\n",
       "      <td>0.581560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_leaf  train_acc   val_acc\n",
       "4         4.0                 1   0.597395  0.598109\n",
       "5         4.0                 3   0.595027  0.598109\n",
       "6         4.0                 5   0.594435  0.595745\n",
       "10        5.0                 5   0.608052  0.595745\n",
       "9         5.0                 3   0.611012  0.593381\n",
       "7         4.0                10   0.593250  0.591017\n",
       "14        6.0                 5   0.621078  0.581560\n",
       "8         5.0                 1   0.614565  0.581560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.629959</td>\n",
       "      <td>0.612293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.673179</td>\n",
       "      <td>0.602837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.714624</td>\n",
       "      <td>0.600473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.616341</td>\n",
       "      <td>0.593381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.806986</td>\n",
       "      <td>0.591017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.775015</td>\n",
       "      <td>0.588652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.841918</td>\n",
       "      <td>0.574468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.822972</td>\n",
       "      <td>0.565012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C  gamma  train_acc   val_acc\n",
       "3  1.0  scale   0.629959  0.612293\n",
       "6  2.0  scale   0.673179  0.602837\n",
       "2  0.5   0.05   0.714624  0.600473\n",
       "0  0.5  scale   0.616341  0.593381\n",
       "1  0.5    0.1   0.806986  0.591017\n",
       "5  1.0   0.05   0.775015  0.588652\n",
       "4  1.0    0.1   0.841918  0.574468\n",
       "8  2.0   0.05   0.822972  0.565012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def evaluate_grid(model_ctor, grid, Xtr, ytr, Xva, yva, dense=False):\n",
    "    if dense:\n",
    "        Xtr = to_dense(Xtr); Xva = to_dense(Xva)\n",
    "    rows = []\n",
    "    for params in ParameterGrid(grid):\n",
    "        mdl = model_ctor(**params)\n",
    "        mdl.fit(Xtr, ytr)\n",
    "        yhat_tr = mdl.predict(Xtr)\n",
    "        yhat_va = mdl.predict(Xva)\n",
    "        rows.append({\n",
    "            **params,\n",
    "            \"train_acc\": accuracy_score(ytr, yhat_tr),\n",
    "            \"val_acc\":   accuracy_score(yva, yhat_va)\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"val_acc\", ascending=False)\n",
    "\n",
    "# Tree sweep\n",
    "tree_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 6, 8, None],\n",
    "    \"min_samples_leaf\": [1, 3, 5, 10]\n",
    "}\n",
    "tree_df = evaluate_grid(lambda **p: DecisionTreeClassifier(random_state=42, **p),\n",
    "                        tree_grid, X_tr, y_tr, X_va, y_va, dense=True)\n",
    "display(tree_df.head(8))\n",
    "\n",
    "# SVM sweep (small)\n",
    "svm_grid = {\n",
    "    \"C\": [0.5, 1.0, 2.0, 4.0],\n",
    "    \"gamma\": ['scale', 0.1, 0.05]\n",
    "}\n",
    "svm_df = evaluate_grid(lambda **p: SVC(probability=True, class_weight='balanced', random_state=42, **p),\n",
    "                       svm_grid, X_tr, y_tr, X_va, y_va, dense=True)\n",
    "display(svm_df.head(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Examples\n",
    "### Show sampled y_true, y_pred, and probabilities for all splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>p_homewin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.609540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.589909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.568729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_true  y_pred  p_homewin\n",
       "988        1       1   0.609540\n",
       "1634       1       1   0.589909\n",
       "752        0       0   0.472549\n",
       "1422       1       1   0.568729\n",
       "764        0       0   0.452872\n",
       "78         1       0   0.465177\n",
       "1541       1       0   0.426243\n",
       "383        1       1   0.580343\n",
       "1009       1       0   0.462121\n",
       "69         0       0   0.426343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>p_homewin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.423383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true  y_pred  p_homewin\n",
       "145       1       0   0.423383\n",
       "280       0       1   0.546930\n",
       "175       0       1   0.545782\n",
       "410       1       1   0.588725\n",
       "419       1       1   0.534526\n",
       "73        0       1   0.552299\n",
       "132       0       1   0.597333\n",
       "137       0       1   0.523262\n",
       "30        1       1   0.549760\n",
       "72        1       0   0.474625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>p_homewin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.402856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.627106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.599671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true  y_pred  p_homewin\n",
       "158       0       0   0.402856\n",
       "395       1       1   0.589041\n",
       "6         0       0   0.477744\n",
       "417       1       1   0.529468\n",
       "79        0       0   0.440574\n",
       "220       0       1   0.570055\n",
       "527       1       1   0.627106\n",
       "493       1       1   0.580932\n",
       "329       1       1   0.599671\n",
       "104       0       0   0.438289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample_preds(model, X, y, split_name, n=10):\n",
    "    Xd = to_dense(X)\n",
    "    yhat = model.predict(Xd)\n",
    "    try:\n",
    "        p1 = model.predict_proba(Xd)[:,1]\n",
    "    except Exception:\n",
    "        p1 = np.full_like(yhat, fill_value=np.nan, dtype='float64')\n",
    "    out = pd.DataFrame({\"y_true\": y, \"y_pred\": yhat, \"p_homewin\": p1})\n",
    "    print(f\"\\n{split_name} sample predictions:\")\n",
    "    display(out.sample(min(n, len(out)), random_state=42))\n",
    "\n",
    "sample_preds(best_model, X_tr, y_tr, \"TRAIN\")\n",
    "sample_preds(best_model, X_va, y_va, \"VALIDATION\")\n",
    "sample_preds(best_model, X_te, y_te, \"TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Diagnosis & Next Steps\n",
    "### Place the model on the biasâ€“variance curve; propose improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>gap</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.070</td>\n",
       "      <td>Near sweet-spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.598</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>Near sweet-spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.012</td>\n",
       "      <td>Near sweet-spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.079</td>\n",
       "      <td>Near sweet-spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  train_acc  val_acc    gap        diagnosis\n",
       "0       SVM_RBF      0.673    0.603  0.070  Near sweet-spot\n",
       "1    NaiveBayes      0.591    0.598 -0.007  Near sweet-spot\n",
       "2  DecisionTree      0.608    0.596  0.012  Near sweet-spot\n",
       "3           KNN      0.647    0.567  0.079  Near sweet-spot"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVM_RBF\n",
      "Train acc=0.673  Val acc=0.603  Gap=0.070\n",
      "Diagnosis: Near sweet-spot\n",
      "\n",
      "Next steps:\n",
      "- Small hyperparam polish (narrow grid around current best).\n",
      "- Feature enrichment: last-7/10/15 win%, rolling runs scored/allowed, opponent-adjusted stats.\n",
      "- Compare RandomForest vs tuned SVM; keep temporal CV.\n"
     ]
    }
   ],
   "source": [
    "def fit_position(train_acc, val_acc, baseline, gap_thresh=0.08, lift=0.03):\n",
    "    gap = train_acc - val_acc\n",
    "    if val_acc < baseline + lift and train_acc < baseline + lift:\n",
    "        return \"Underfitting (high bias)\"\n",
    "    if gap > gap_thresh and train_acc >= baseline + lift:\n",
    "        return \"Overfitting (high variance)\"\n",
    "    return \"Near sweet-spot\"\n",
    "\n",
    "def next_steps_for(model_name, diagnosis):\n",
    "    if \"Underfitting\" in diagnosis:\n",
    "        return (\n",
    "            \"- Increase capacity: SVM (RBF) with larger C, DecisionTree deeper (with pruning), or KNN with smaller k.\\n\"\n",
    "            \"- Add features: rolling form (last-7/10/15), opponent-adjusted z-scores, more matchup ratios/deltas.\\n\"\n",
    "            \"- Try RandomForest (bagging trees) to gain capacity without brittle splits.\"\n",
    "        )\n",
    "    if \"Overfitting\" in diagnosis:\n",
    "        return (\n",
    "            \"- Regularize: for SVM lower C; for DT prune (max_depth, min_samples_leaf, ccp_alpha).\\n\"\n",
    "            \"- Bagging with RandomForest to reduce variance; keep trees shallow-ish.\\n\"\n",
    "            \"- Reduce noisy features or cap poly interactions; use stronger CV.\"\n",
    "        )\n",
    "    return (\n",
    "        \"- Small hyperparam polish (narrow grid around current best).\\n\"\n",
    "        \"- Feature enrichment: last-7/10/15 win%, rolling runs scored/allowed, opponent-adjusted stats.\\n\"\n",
    "        \"- Compare RandomForest vs tuned SVM; keep temporal CV.\"\n",
    "    )\n",
    "\n",
    "baseline = max(np.mean(y_tr == 0), np.mean(y_tr == 1))\n",
    "\n",
    "diag_rows = []\n",
    "for _, r in summary.iterrows():\n",
    "    diagnosis = fit_position(r['train_acc'], r['val_acc'], baseline)\n",
    "    diag_rows.append({\n",
    "        'model': r['model'],\n",
    "        'train_acc': round(r['train_acc'], 3),\n",
    "        'val_acc': round(r['val_acc'], 3),\n",
    "        'gap': round(r['train_acc'] - r['val_acc'], 3),\n",
    "        'diagnosis': diagnosis\n",
    "    })\n",
    "diag_df = pd.DataFrame(diag_rows).sort_values(['val_acc','train_acc'], ascending=False)\n",
    "display(diag_df.head(6))\n",
    "\n",
    "best = diag_df.iloc[0]\n",
    "print(f\"Best model: {best['model']}\")\n",
    "print(f\"Train acc={best['train_acc']:.3f}  Val acc={best['val_acc']:.3f}  Gap={best['gap']:.3f}\")\n",
    "print(\"Diagnosis:\", best['diagnosis'])\n",
    "print(\"\\nNext steps:\\n\" + next_steps_for(best['model'], best['diagnosis']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of First Model\n",
    "\n",
    "#### Summarize performance and concrete improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### We trained multiple allowed models (Decision Tree, KNN, SVM (RBF), Naive Bayes) on leakage-safe, engineered features and selected the best model by validation accuracy to avoid test peeking. The chosen model shows consistent generalization (train vs. validation close), indicating it is not severely overfitting. Test results are in line with validation, suggesting our preprocessing and temporal split are sound.\n",
    "\n",
    "Improvement:\n",
    "###### Richer features: opponent-adjusted stats (z-scores vs league), rolling runs scored/allowed, separate last-7/10/15 windows, and home/away form asymmetry.\n",
    "\n",
    "###### Modeling: compare RandomForest (variance reduction over a single tree) vs a tuned SVM (RBF); keep selection on validation only.\n",
    "\n",
    "###### Regularization & tuning: for trees (max_depth, min_samples_leaf, ccp_alpha); for SVM (C, gamma).\n",
    "\n",
    "###### Calibration & thresholding: probability calibration (Platt/Isotonic) and decision thresholds if class costs differ.\n",
    "\n",
    "###### Temporal CV: use walk-forward/blocked CV on the training period for more robust hyperparameter selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
