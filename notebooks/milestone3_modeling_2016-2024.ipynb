{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3 â€” Pre-Processing & First Model \n",
    "MLB Game Prediction: Data Ingestion, Preprocessing, and Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion and Assembly \n",
    "\n",
    "### We fetch live game data and team statistics, merging them into a single DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pybaseball import team_batting, team_pitching, cache\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=r\".*pybaseball.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\"Could not infer format.*\")\n",
    "\n",
    "cache.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching game data...\n",
      "Game data shape: (19436, 15)\n",
      "Fetching team stats...\n",
      "Fixed 'g' shape: (19436, 29)\n",
      "Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "# Do not run this cell, data has already been stored in csv\n",
    "\n",
    "SEASONS = [2016, 2017, 2018, 2019, 2021, 2022, 2023, 2024] # exclude 2020/Covid\n",
    "TEAMS = ['ARI','ATL','BAL','BOS','CHC','CHW','CIN','CLE','COL','DET','HOU','KCR','LAA','LAD','MIA','MIL','MIN','NYM','NYY','OAK','PHI','PIT','SDP','SEA','SFG','STL','TBR','TEX','TOR','WSN']\n",
    "\n",
    "\n",
    "TEAM_LEAGUE = {\n",
    "    'ARI':'NL','ATL':'NL','BAL':'AL','BOS':'AL','CHC':'NL','CHW':'AL','CIN':'NL','CLE':'AL',\n",
    "    'COL':'NL','DET':'AL','HOU':'AL','KCR':'AL','LAA':'AL','LAD':'NL','MIA':'NL','MIL':'NL',\n",
    "    'MIN':'AL','NYM':'NL','NYY':'AL','OAK':'AL','PHI':'NL','PIT':'NL','SDP':'NL','SEA':'AL',\n",
    "    'SFG':'NL','STL':'NL','TBR':'AL','TEX':'AL','TOR':'AL','WSN':'NL'\n",
    "}\n",
    "STATS_ABBR = { 'ARI':'ARI','ATL':'ATL','BAL':'BAL','BOS':'BOS','CHC':'CHC','CHW':'CWS','CIN':'CIN','CLE':'CLE', 'COL':'COL','DET':'DET','HOU':'HOU','KCR':'KC','LAA':'LAA','LAD':'LAD','MIA':'MIA','MIL':'MIL', 'MIN':'MIN','NYM':'NYM','NYY':'NYY','OAK':'OAK','PHI':'PHI','PIT':'PIT','SDP':'SD','SEA':'SEA', 'SFG':'SF','STL':'STL','TBR':'TB','TEX':'TEX','TOR':'TOR','WSN':'WSH' }\n",
    "INVERSE_STATS_ABBR = {v: k for k, v in STATS_ABBR.items()}\n",
    "STATIC_ABBR_TO_ID = {\n",
    "    'ARI':109, 'ATL':144, 'BAL':110, 'BOS':111, 'CHC':112, 'CWS':145, 'CIN':113, 'CLE':114,\n",
    "    'COL':115, 'DET':116, 'HOU':117, 'KC':118, 'LAA':108, 'LAD':119, 'MIA':146, 'MIL':158,\n",
    "    'MIN':142, 'NYM':121, 'NYY':147, 'OAK':133, 'PHI':143, 'PIT':134, 'SD':135, 'SEA':136,\n",
    "    'SF':137, 'STL':138, 'TB':139, 'TEX':140, 'TOR':141, 'WSH':120\n",
    "}\n",
    "ABBR_TO_NAME = {\n",
    "    'ARI':'Arizona Diamondbacks','ATL':'Atlanta Braves','BAL':'Baltimore Orioles','BOS':'Boston Red Sox',\n",
    "    'CHC':'Chicago Cubs','CHW':'Chicago White Sox','CIN':'Cincinnati Reds','CLE':'Cleveland Guardians',\n",
    "    'COL':'Colorado Rockies','DET':'Detroit Tigers','HOU':'Houston Astros','KCR':'Kansas City Royals',\n",
    "    'LAA':'Los Angeles Angels','LAD':'Los Angeles Dodgers','MIA':'Miami Marlins','MIL':'Milwaukee Brewers',\n",
    "    'MIN':'Minnesota Twins','NYM':'New York Mets','NYY':'New York Yankees','OAK':'Oakland Athletics',\n",
    "    'PHI':'Philadelphia Phillies','PIT':'Pittsburgh Pirates','SDP':'San Diego Padres','SEA':'Seattle Mariners',\n",
    "    'SFG':'San Francisco Giants','STL':'St. Louis Cardinals','TBR':'Tampa Bay Rays','TEX':'Texas Rangers',\n",
    "    'TOR':'Toronto Blue Jays','WSN':'Washington Nationals'\n",
    "}\n",
    "NAME_TO_ABBR = {v: k for k, v in ABBR_TO_NAME.items()}\n",
    "ALIASES = {'WSH':'WSN','TB':'TBR','SD':'SDP','KC':'KCR','CWS':'CHW','SF':'SFG','AZ':'ARI'}\n",
    "\n",
    "_ID_BY_ABBR = {}\n",
    "_ABBR_BY_ID = {}\n",
    "\n",
    "def _init_team_maps(season: int):\n",
    "    global _ID_BY_ABBR, _ABBR_BY_ID\n",
    "    if _ID_BY_ABBR: return\n",
    "    api_abbr_to_id = {}\n",
    "    for params in ({\"sportId\": 1, \"season\": season}, {\"sportId\": 1}):\n",
    "        try:\n",
    "            r = requests.get(\"https://statsapi.mlb.com/api/v1/teams\", params=params, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            teams = r.json().get(\"teams\", [])\n",
    "            api_abbr_to_id = {t.get(\"abbreviation\"): t.get(\"id\") for t in teams if t.get(\"abbreviation\") and t.get(\"id\")}\n",
    "            if api_abbr_to_id: break\n",
    "        except Exception: continue\n",
    "    merged = dict(STATIC_ABBR_TO_ID)\n",
    "    merged.update(api_abbr_to_id)\n",
    "    _ABBR_BY_ID = {tid: abbr for abbr, tid in merged.items()}\n",
    "    _ID_BY_ABBR = {mine: merged[api] for mine, api in STATS_ABBR.items()}\n",
    "\n",
    "def _fetch_sched(season, team):\n",
    "    _init_team_maps(season)\n",
    "    tid = _ID_BY_ABBR.get(team)\n",
    "    if tid is None: raise KeyError(team)\n",
    "    r = requests.get(\"https://statsapi.mlb.com/api/v1/schedule\", params={\"sportId\": 1, \"teamId\": tid, \"startDate\": f\"03/01/{season}\", \"endDate\": f\"12/31/{season}\", \"gameType\": \"R\"}, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    games = []\n",
    "    for d in data.get(\"dates\", []):\n",
    "        for g in d.get(\"games\", []):\n",
    "            tm = g.get(\"teams\", {})\n",
    "            home, away = tm.get(\"home\", {}), tm.get(\"away\", {})\n",
    "            \n",
    "            games.append({\n",
    "                \"game_pk\": g.get(\"gamePk\"), \"game_date\": d.get(\"date\"),\n",
    "                \"home_id\": (home.get(\"team\") or {}).get(\"id\"), \"away_id\": (away.get(\"team\") or {}).get(\"id\"),\n",
    "                \"home_score\": home.get(\"score\"), \"away_score\": away.get(\"score\"),\n",
    "                \"game_num\": g.get(\"gameNumber\"), \"day_night\": g.get(\"dayNight\")\n",
    "            })\n",
    "    df = pd.DataFrame(games)\n",
    "    if df.empty: return df\n",
    "    is_home = df[\"home_id\"].eq(tid)\n",
    "    opp = df[\"away_id\"].map(_ABBR_BY_ID).where(is_home, df[\"home_id\"].map(_ABBR_BY_ID)).astype(object)\n",
    "    idx = df.index\n",
    "    out = pd.DataFrame(index=idx)\n",
    "    out[\"Tm\"] = pd.Series(team, index=idx, dtype=object)\n",
    "    out[\"Opp\"] = opp\n",
    "    out[\"Home_Away\"] = pd.Series(np.where(is_home, \"\", \"@\"), index=idx, dtype=object)\n",
    "    out[\"Date\"] = pd.to_datetime(df[\"game_date\"], errors=\"coerce\").dt.strftime(\"%b %d\")\n",
    "    out[\"R\"] = pd.to_numeric(df[\"home_score\"].where(is_home, df[\"away_score\"]), errors=\"coerce\")\n",
    "    out[\"RA\"] = pd.to_numeric(df[\"away_score\"].where(is_home, df[\"home_score\"]), errors=\"coerce\")\n",
    "    out[\"game_id\"] = df[\"game_pk\"]\n",
    "    \n",
    "    out[\"D/N\"] = df[\"day_night\"]\n",
    "    return out[[\"Tm\", \"Opp\", \"Date\", \"R\", \"RA\", \"Home_Away\", \"D/N\", \"game_id\"]]\n",
    "\n",
    "def _parse_bbref_date(raw_series: pd.Series, season: int) -> pd.Series:\n",
    "    s = raw_series.astype(str).str.replace(r\"\\\\(.*?\\\\)\", \"\", regex=True).str.replace(r\"^[A-Za-z]{3,9},\\\\s*\", \"\", regex=True).str.strip() + f\" {season}\"\n",
    "    return pd.to_datetime(s, format=\"%b %d %Y\", errors=\"coerce\")\n",
    "\n",
    "def _parse_day_night(x):\n",
    "    x_str = str(x).strip().upper()\n",
    "    if x_str in (\"D\", \"DAY\"): return \"Day\"\n",
    "    if x_str in (\"N\", \"NIGHT\"): return \"Night\"\n",
    "    return None\n",
    "\n",
    "def load_games_for_season(season: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for tm in TEAMS:\n",
    "        df = _fetch_sched(season, tm)\n",
    "        if df is None or df.empty: continue\n",
    "        df = df[~df[\"Home_Away\"].astype(str).str.contains(\"@\")]\n",
    "        df = df[df[\"R\"].notna() & df[\"RA\"].notna()].copy()\n",
    "        df[\"date\"] = _parse_bbref_date(df[\"Date\"], season)\n",
    "        df = df.rename(columns={\"Tm\":\"home_team\",\"Opp\":\"away_team\",\"R\":\"home_runs\",\"RA\":\"away_runs\"})\n",
    "        df[\"away_team\"] = df[\"away_team\"].map(INVERSE_STATS_ABBR).fillna(df[\"away_team\"])\n",
    "        df[\"home_win\"] = (df[\"home_runs\"] > df[\"away_runs\"]).astype(int)\n",
    "        df[\"season\"] = season\n",
    "        \n",
    "        df[\"day_night\"] = df[\"D/N\"].apply(_parse_day_night)\n",
    "        df[\"run_diff\"] = df[\"home_runs\"] - df[\"away_runs\"]\n",
    "        df[\"month\"] = df[\"date\"].dt.month\n",
    "        df[\"weekday\"] = df[\"date\"].dt.day_name()\n",
    "        df[\"home_league\"] = df[\"home_team\"].map(TEAM_LEAGUE)\n",
    "        df[\"away_league\"] = df[\"away_team\"].map(TEAM_LEAGUE)\n",
    "        df[\"is_interleague\"] = (df[\"home_league\"] != df[\"away_league\"]).astype(int)\n",
    "        \n",
    "        keep_cols = [\"season\",\"date\",\"home_team\",\"away_team\",\"home_runs\",\"away_runs\",\"home_win\",\"run_diff\",\"month\",\"weekday\",\"day_night\",\"home_league\",\"away_league\",\"is_interleague\",\"game_id\"]\n",
    "        rows.append(df[[c for c in keep_cols if c in df.columns]])\n",
    "    out = pd.concat(rows, ignore_index=True).dropna(subset=[\"date\"])\n",
    "    out = out.drop_duplicates(subset=[\"game_id\"])\n",
    "    return out.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def normalize_team_key(df: pd.DataFrame, team_col: str = \"Team\") -> pd.Series:\n",
    "    vals = df[team_col].astype(str).str.strip().str.replace(r\"\\\\s*\\\\(.*\\\\)$\", \"\", regex=True)\n",
    "    if vals.isin(set(ABBR_TO_NAME.keys())).mean() >= 0.9: return vals.replace(ALIASES)\n",
    "    return vals.map(NAME_TO_ABBR)\n",
    "\n",
    "def team_batting_minimal(season: int) -> pd.DataFrame:\n",
    "    tb = team_batting(season).copy()\n",
    "    tb.columns = tb.columns.str.strip()\n",
    "    if \"BA\" not in tb.columns and \"AVG\" in tb.columns:\n",
    "        tb = tb.rename(columns={\"AVG\": \"BA\"})\n",
    "    if \"OPS\" not in tb.columns and {\"OBP\",\"SLG\"}.issubset(tb.columns): tb[\"OPS\"] = tb[\"OBP\"] + tb[\"SLG\"]\n",
    "    keep = [c for c in [\"Team\",\"BA\",\"OBP\",\"SLG\",\"OPS\",\"R\"] if c in tb.columns]\n",
    "    tb = tb[keep].rename(columns={\"R\":\"season_runs\"})\n",
    "    tb[\"team\"] = normalize_team_key(tb, \"Team\")\n",
    "    return tb[[\"team\",\"BA\",\"OBP\",\"SLG\",\"OPS\",\"season_runs\"]]\n",
    "\n",
    "def team_pitching_minimal(season: int) -> pd.DataFrame:\n",
    "    tp = team_pitching(season).copy()\n",
    "    tp.columns = tp.columns.str.strip()\n",
    "    keep = [c for c in [\"Team\",\"ERA\",\"WHIP\"] if c in tp.columns]\n",
    "    tp = tp[keep]\n",
    "    tp[\"team\"] = normalize_team_key(tp, \"Team\")\n",
    "    return tp[[\"team\",\"ERA\",\"WHIP\"]]\n",
    "\n",
    "# --- Execute Data Loading ---\n",
    "print(\"Fetching game data...\")\n",
    "games = pd.concat([load_games_for_season(y) for y in SEASONS], ignore_index=True)\n",
    "print(\"Game data shape:\", games.shape)\n",
    "\n",
    "print(\"Fetching team stats...\")\n",
    "bat = pd.concat([team_batting_minimal(y).assign(season=y) for y in SEASONS], ignore_index=True)\n",
    "pit = pd.concat([team_pitching_minimal(y).assign(season=y) for y in SEASONS], ignore_index=True)\n",
    "\n",
    "team_stats = (\n",
    "    bat.merge(pit, on=['team','season'], how='inner')\n",
    "       .query('team in @TEAMS')  # keep only MLB clubs\n",
    ")\n",
    "\n",
    "# Build prefixed home/away views\n",
    "home_stats = (\n",
    "    team_stats.rename(columns={'team':'home_team'})\n",
    "              .rename(columns={c: f'home_{c}' for c in team_stats.columns if c not in ['team','season']})\n",
    ")\n",
    "away_stats = (\n",
    "    team_stats.rename(columns={'team':'away_team'})\n",
    "              .rename(columns={c: f'away_{c}' for c in team_stats.columns if c not in ['team','season']})\n",
    ")\n",
    "\n",
    "# Merge by (team, season) to avoid row blow-up\n",
    "g = games.merge(home_stats, on=['home_team','season'], how='left') \\\n",
    "         .merge(away_stats, on=['away_team','season'], how='left')\n",
    "\n",
    "print(\"Fixed 'g' shape:\", g.shape)  # should be ~ same # rows as `games`\n",
    "\n",
    "print(\"Data loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run if data already stored\n",
    "\n",
    "out_path = Path('../data/raw') / 'games_2016-2024_Milestone3.csv'\n",
    "g.to_csv(out_path, index=False); out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Modeling\n",
    "### Clean data, add matchup features, split into train/val/test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/games_2016-2024_Milestone3.csv\").reset_index(drop=True)\n",
    "\n",
    "# -- 1) Drop outcome-leakers if present\n",
    "leakers = [c for c in ['home_runs','away_runs','run_diff','home_score','away_score'] if c in df.columns]\n",
    "df = df.drop(columns=leakers, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcast numeric to float32 to cut memory\n",
    "for c in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[c]):\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  Train: (13591, 81)  Val: (3397, 81)  Test: (4248, 81)\n",
      "  Class balance: {np.int64(0): np.int64(6357), np.int64(1): np.int64(7234)}\n"
     ]
    }
   ],
   "source": [
    "# -- 2) Feature expansion: diffs, ratios (safe divide), ERA-advantage\n",
    "def _safe_div(a, b):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        r = np.divide(a, b, where=(b!=0))\n",
    "        r[~np.isfinite(r)] = 0.0\n",
    "    return r\n",
    "\n",
    "for sfx in ['OPS','ERA','WHIP','BA']:\n",
    "    h, a = f'home_{sfx}', f'away_{sfx}'\n",
    "    if h in df.columns and a in df.columns:\n",
    "        df[f'delta_{sfx.lower()}'] = df[h] - df[a]\n",
    "        df[f'ratio_{sfx.lower()}'] = _safe_div(df[h].to_numpy(), df[a].to_numpy())\n",
    "        if sfx == 'ERA':\n",
    "            df['adv_era'] = df[a] - df[h]  \n",
    "\n",
    "def add_rolling_form(df, date_col, ks=(10, 7, 15)):\n",
    "    \"\"\"\n",
    "    Adds home_last{k}_win_pct and away_last{k}_win_pct for each k.\n",
    "    Leakage-safe via shift(1): only prior games count.\n",
    "    \"\"\"\n",
    "    req = {'home_team', 'away_team', 'home_win', date_col}\n",
    "    if not req.issubset(df.columns):\n",
    "        return df  \n",
    "\n",
    "    out = df.copy()\n",
    "    out[date_col] = pd.to_datetime(out[date_col], errors='coerce')\n",
    "\n",
    "    \n",
    "    home = out[[date_col, 'home_team', 'home_win']].rename(\n",
    "        columns={'home_team': 'team', 'home_win': 'team_win'}\n",
    "    )\n",
    "    home['is_home'] = 1\n",
    "\n",
    "    away = out[[date_col, 'away_team', 'home_win']].rename(\n",
    "        columns={'away_team': 'team'}\n",
    "    )\n",
    "    away['team_win'] = 1 - away['home_win']  \n",
    "    away['is_home'] = 0\n",
    "\n",
    "    long = pd.concat([home, away], ignore_index=True)\n",
    "    long = long.sort_values(['team', date_col])\n",
    "\n",
    "    # Rolling win% for prior k games\n",
    "    for k in ks:\n",
    "        long[f'last{k}_win_pct'] = (\n",
    "            long.groupby('team', group_keys=False)['team_win']\n",
    "                .apply(lambda s: s.shift(1).rolling(window=k, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "    # Split back to home/away and merge to original\n",
    "    home_cols = [date_col, 'team'] + [f'last{k}_win_pct' for k in ks]\n",
    "    away_cols = home_cols.copy()\n",
    "\n",
    "    home_form = (long[long['is_home'] == 1][home_cols]\n",
    "                 .rename(columns={'team': 'home_team', **{f'last{k}_win_pct': f'home_last{k}_win_pct' for k in ks}}))\n",
    "    away_form = (long[long['is_home'] == 0][away_cols]\n",
    "                 .rename(columns={'team': 'away_team', **{f'last{k}_win_pct': f'away_last{k}_win_pct' for k in ks}}))\n",
    "\n",
    "    out = out.merge(home_form, on=[date_col, 'home_team'], how='left')\n",
    "    out = out.merge(away_form, on=[date_col, 'away_team'], how='left')\n",
    "\n",
    "    \n",
    "    return out\n",
    "\n",
    "date_col = next((c for c in ['date','game_date'] if c in df.columns), None)\n",
    "\n",
    "if date_col:\n",
    "    df = add_rolling_form(df, date_col=date_col, ks=(10, 7, 15))\n",
    "\n",
    "# -- 3) Column groups\n",
    "target = 'home_win'\n",
    "assert target in df.columns, \"home_win target missing.\"\n",
    "id_cols = [c for c in ['season','date','game_id'] if c in df.columns]\n",
    "cat_cols = [c for c in ['day_night','weekday','home_league','away_league','is_interleague','is_doubleheader','venue'] if c in df.columns]\n",
    "bool_cols = [c for c in df.columns if pd.api.types.is_bool_dtype(df[c])]\n",
    "num_cols = [c for c in df.columns\n",
    "            if c not in ([target] + id_cols + cat_cols + bool_cols)\n",
    "            and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "# -- Tiny degree-2 interactions on high-signal features\n",
    "# -- Tiny degree-2 interactions on high-signal features (select only a few)\n",
    "poly_base = [c for c in df.columns if c.startswith(('delta_','ratio_','adv_'))][:8]\n",
    "\n",
    "# -- Preprocessor blocks\n",
    "num_cols_all = [c for c in df.columns\n",
    "                if c not in ([target] + id_cols + cat_cols + bool_cols)\n",
    "                and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "# Split numeric columns into those we want poly on vs the rest\n",
    "num_poly_cols = [c for c in num_cols_all if c in poly_base]\n",
    "num_rest_cols = [c for c in num_cols_all if c not in num_poly_cols]\n",
    "\n",
    "num_rest_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "num_poly_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),             \n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe  = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "bool_pipe = Pipeline([\n",
    "    ('to_float', FunctionTransformer(lambda X: X.astype('float64'))),\n",
    "    ('impute', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Build ColumnTransformer: poly only applied to num_poly_cols, rest scaled normally\n",
    "transformers = []\n",
    "if num_rest_cols: transformers.append(('num',      num_rest_pipe, num_rest_cols))\n",
    "if num_poly_cols: transformers.append(('num_poly', num_poly_pipe, num_poly_cols))\n",
    "if cat_cols:      transformers.append(('cat',      cat_pipe,      cat_cols))\n",
    "if bool_cols:     transformers.append(('bool',     bool_pipe,     bool_cols))\n",
    "\n",
    "pre = ColumnTransformer(transformers, remainder='drop', sparse_threshold=0.3)\n",
    "\n",
    "# -- Design matrix/labels (unchanged)\n",
    "X_raw = df.drop(columns=[target] + id_cols, errors='ignore').copy()\n",
    "y = df[target].astype(int).values\n",
    "def time_split(Xdf, y, date_series=None, train=0.64, val=0.16, test=0.20, random_state=42):\n",
    "    \"\"\"\n",
    "    If date_series is provided, sorts by time and slices (train, val, test).\n",
    "    Otherwise, uses stratified random splits that preserve class balance.\n",
    "    \"\"\"\n",
    "    assert abs(train + val + test - 1.0) < 1e-8, \"Splits must sum to 1.\"\n",
    "\n",
    "    if date_series is not None:\n",
    "        ds = pd.to_datetime(date_series, errors='coerce')\n",
    "        order = np.argsort(ds.fillna(pd.Timestamp.min).values)\n",
    "        X_sorted = Xdf.iloc[order].reset_index(drop=True)\n",
    "        y_sorted = y[order]\n",
    "        n = len(X_sorted)\n",
    "        a = int(n * train)\n",
    "        b = int(n * (train + val))\n",
    "        return (\n",
    "            X_sorted.iloc[:a], X_sorted.iloc[a:b], X_sorted.iloc[b:],\n",
    "            y_sorted[:a],      y_sorted[a:b],      y_sorted[b:]\n",
    "        )\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        Xdf, y, test_size=test, random_state=random_state, stratify=y\n",
    "    )\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "        X_tr, y_tr, test_size=val/(1-test), random_state=random_state, stratify=y_tr\n",
    "    )\n",
    "    return X_tr, X_va, X_te, y_tr, y_va, y_te\n",
    "\n",
    "\n",
    "\n",
    "X_tr_raw, X_va_raw, X_te_raw, y_tr, y_va, y_te = time_split(\n",
    "    X_raw, y, date_series=df[date_col] if date_col else None\n",
    ")\n",
    "\n",
    "X_tr = pre.fit_transform(X_tr_raw)\n",
    "X_va = pre.transform(X_va_raw)\n",
    "X_te = pre.transform(X_te_raw)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  Train:\", X_tr.shape, \" Val:\", X_va.shape, \" Test:\", X_te.shape)\n",
    "print(\"  Class balance:\", dict(zip(*np.unique(y_tr, return_counts=True))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models & Metrics\n",
    "\n",
    "### Train Decision Tree, KNN, SVM (RBF), and Naive Bayes; compare splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "      <td>0.579802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>0.623354</td>\n",
       "      <td>0.584045</td>\n",
       "      <td>0.570151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.605401</td>\n",
       "      <td>0.580512</td>\n",
       "      <td>0.563795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.642410</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.540490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  train_acc   val_acc  test_acc\n",
       "3    NaiveBayes   0.588404  0.595231  0.579802\n",
       "2       SVM_RBF   0.623354  0.584045  0.570151\n",
       "0  DecisionTree   0.605401  0.580512  0.563795\n",
       "1           KNN   0.642410  0.546364  0.540490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen model based on Val Acc: NaiveBayes\n",
      "Val balanced_acc: 0.5896169498724094\n",
      "Val macro_f1: 0.5888866151330917\n",
      "Test balanced_acc: 0.5767958227601016\n",
      "Test macro_f1: 0.5726647889724266\n",
      "\n",
      "Validation classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Away(0)       0.58      0.50      0.54      1587\n",
      "     Home(1)       0.61      0.68      0.64      1810\n",
      "\n",
      "    accuracy                           0.60      3397\n",
      "   macro avg       0.59      0.59      0.59      3397\n",
      "weighted avg       0.59      0.60      0.59      3397\n",
      "\n",
      "Validation confusion matrix:\n",
      " [[ 800  787]\n",
      " [ 588 1222]]\n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Away(0)       0.59      0.46      0.52      2068\n",
      "     Home(1)       0.58      0.69      0.63      2180\n",
      "\n",
      "    accuracy                           0.58      4248\n",
      "   macro avg       0.58      0.58      0.57      4248\n",
      "weighted avg       0.58      0.58      0.57      4248\n",
      "\n",
      "Test confusion matrix:\n",
      " [[ 957 1111]\n",
      " [ 674 1506]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_dense(X):\n",
    "    return X.toarray() if hasattr(X, \"toarray\") else X\n",
    "\n",
    "X_tr_d = to_dense(X_tr)\n",
    "X_va_d = to_dense(X_va)\n",
    "X_te_d = to_dense(X_te)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, random_state=42),\n",
    "    \"KNN\":          KNeighborsClassifier(n_neighbors=15),\n",
    "    \"SVM_RBF\":      SVC(C=2.0, gamma='scale', probability=True, class_weight='balanced', random_state=42),\n",
    "    \"NaiveBayes\":   GaussianNB()\n",
    "}\n",
    "\n",
    "rows = []\n",
    "reports = {}\n",
    "for name, mdl in models.items():\n",
    "    Xtr = X_tr_d if name != \"DecisionTree\" else X_tr_d  # tree also fine with dense\n",
    "    Xva = X_va_d\n",
    "    Xte = X_te_d\n",
    "    mdl.fit(Xtr, y_tr)\n",
    "    yhat_tr = mdl.predict(Xtr)\n",
    "    yhat_va = mdl.predict(Xva)\n",
    "    yhat_te = mdl.predict(Xte)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"train_acc\": accuracy_score(y_tr, yhat_tr),\n",
    "        \"val_acc\":   accuracy_score(y_va, yhat_va),\n",
    "        \"test_acc\":  accuracy_score(y_te, yhat_te),\n",
    "    })\n",
    "\n",
    "    reports[name] = {\n",
    "        \"val_report\":  classification_report(y_va, yhat_va, target_names=['Away(0)','Home(1)']),\n",
    "        \"test_report\": classification_report(y_te, yhat_te, target_names=['Away(0)','Home(1)']),\n",
    "        \"val_cm\":      confusion_matrix(y_va, yhat_va),\n",
    "        \"test_cm\":     confusion_matrix(y_te, yhat_te)\n",
    "    }\n",
    "\n",
    "Xd_va = to_dense(X_va)\n",
    "Xd_te = to_dense(X_te)\n",
    "\n",
    "summary = pd.DataFrame(rows).sort_values(\"val_acc\", ascending=False)\n",
    "display(summary)\n",
    "best_name = summary.iloc[0][\"model\"]\n",
    "best_model = models[best_name]\n",
    "print(f\"\\nChosen model based on Val Acc: {best_name}\")\n",
    "print(\"Val balanced_acc:\", balanced_accuracy_score(y_va, best_model.predict(Xd_va)))\n",
    "print(\"Val macro_f1:\",     f1_score(y_va, best_model.predict(Xd_va), average='macro'))\n",
    "print(\"Test balanced_acc:\", balanced_accuracy_score(y_te, best_model.predict(Xd_te)))\n",
    "print(\"Test macro_f1:\",     f1_score(y_te, best_model.predict(Xd_te), average='macro'))\n",
    "print(\"\\nValidation classification report:\\n\", reports[best_name][\"val_report\"])\n",
    "print(\"Validation confusion matrix:\\n\", reports[best_name][\"val_cm\"])\n",
    "print(\"\\nTest classification report:\\n\", reports[best_name][\"test_report\"])\n",
    "print(\"Test confusion matrix:\\n\", reports[best_name][\"test_cm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596351</td>\n",
       "      <td>0.583750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.596351</td>\n",
       "      <td>0.583750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.596351</td>\n",
       "      <td>0.583750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.595909</td>\n",
       "      <td>0.582573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.604518</td>\n",
       "      <td>0.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605474</td>\n",
       "      <td>0.580512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.605401</td>\n",
       "      <td>0.580512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.605401</td>\n",
       "      <td>0.580512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_leaf  train_acc   val_acc\n",
       "4         4.0                 1   0.596351  0.583750\n",
       "5         4.0                 3   0.596351  0.583750\n",
       "6         4.0                 5   0.596351  0.583750\n",
       "7         4.0                10   0.595909  0.582573\n",
       "11        5.0                10   0.604518  0.582278\n",
       "8         5.0                 1   0.605474  0.580512\n",
       "9         5.0                 3   0.605401  0.580512\n",
       "10        5.0                 5   0.605401  0.580512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.608123</td>\n",
       "      <td>0.585222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.623354</td>\n",
       "      <td>0.584045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.600103</td>\n",
       "      <td>0.583750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.656905</td>\n",
       "      <td>0.582573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.707306</td>\n",
       "      <td>0.574919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.649621</td>\n",
       "      <td>0.566382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.732249</td>\n",
       "      <td>0.564616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.814142</td>\n",
       "      <td>0.556668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C  gamma  train_acc   val_acc\n",
       "3  1.0  scale   0.608123  0.585222\n",
       "6  2.0  scale   0.623354  0.584045\n",
       "0  0.5  scale   0.600103  0.583750\n",
       "2  0.5   0.05   0.656905  0.582573\n",
       "5  1.0   0.05   0.707306  0.574919\n",
       "9  4.0  scale   0.649621  0.566382\n",
       "1  0.5    0.1   0.732249  0.564616\n",
       "4  1.0    0.1   0.814142  0.556668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.162278e-12</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.162278e-11</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.162278e-10</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.162278e-09</td>\n",
       "      <td>0.588404</td>\n",
       "      <td>0.595231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_smoothing  train_acc   val_acc\n",
       "0   1.000000e-12   0.588404  0.595231\n",
       "1   3.162278e-12   0.588404  0.595231\n",
       "2   1.000000e-11   0.588404  0.595231\n",
       "3   3.162278e-11   0.588404  0.595231\n",
       "4   1.000000e-10   0.588404  0.595231\n",
       "5   3.162278e-10   0.588404  0.595231\n",
       "6   1.000000e-09   0.588404  0.595231\n",
       "7   3.162278e-09   0.588404  0.595231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def evaluate_grid(model_ctor, grid, Xtr, ytr, Xva, yva, dense=False):\n",
    "    if dense:\n",
    "        Xtr = to_dense(Xtr); Xva = to_dense(Xva)\n",
    "    rows = []\n",
    "    for params in ParameterGrid(grid):\n",
    "        mdl = model_ctor(**params)\n",
    "        mdl.fit(Xtr, ytr)\n",
    "        yhat_tr = mdl.predict(Xtr)\n",
    "        yhat_va = mdl.predict(Xva)\n",
    "        rows.append({\n",
    "            **params,\n",
    "            \"train_acc\": accuracy_score(ytr, yhat_tr),\n",
    "            \"val_acc\":   accuracy_score(yva, yhat_va)\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"val_acc\", ascending=False)\n",
    "\n",
    "# Tree sweep\n",
    "tree_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 6, 8, None],\n",
    "    \"min_samples_leaf\": [1, 3, 5, 10]\n",
    "}\n",
    "tree_df = evaluate_grid(lambda **p: DecisionTreeClassifier(random_state=42, **p),\n",
    "                        tree_grid, X_tr, y_tr, X_va, y_va, dense=True)\n",
    "display(tree_df.head(8))\n",
    "\n",
    "# SVM sweep (small)\n",
    "svm_grid = {\n",
    "    \"C\": [0.5, 1.0, 2.0, 4.0],\n",
    "    \"gamma\": ['scale', 0.1, 0.05]\n",
    "}\n",
    "svm_df = evaluate_grid(lambda **p: SVC(probability=True, class_weight='balanced', random_state=42, **p),\n",
    "                       svm_grid, X_tr, y_tr, X_va, y_va, dense=True)\n",
    "display(svm_df.head(8))\n",
    "\n",
    "\n",
    "# Naive Bayes sweep (GaussianNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_grid = {\n",
    "    \"var_smoothing\": np.logspace(-12, -6, 13)  # try very small to less-small smoothing\n",
    "}\n",
    "\n",
    "nb_df = evaluate_grid(lambda **p: GaussianNB(**p),\n",
    "                      nb_grid, X_tr, y_tr, X_va, y_va, dense=True)  # NB needs dense\n",
    "display(nb_df.head(8))\n",
    "\n",
    "# best_nb_params = nb_df.iloc[0][list(nb_grid.keys())].to_dict()\n",
    "# best_nb = GaussianNB(**best_nb_params).fit(to_dense(X_tr), y_tr)\n",
    "# print(\"NB val_acc:\", accuracy_score(y_va, best_nb.predict(to_dense(X_va))))\n",
    "# print(\"NB test_acc:\", accuracy_score(y_te, best_nb.predict(to_dense(X_te))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Examples\n",
    "### Show sampled y_true, y_pred, and probabilities for all splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>p_homewin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.867032e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.514070e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.763748e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999994e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.853920e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.451806e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6030</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.031754e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.801218e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.917133e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.904980e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_true  y_pred     p_homewin\n",
       "1061        1       0  2.867032e-01\n",
       "3881        1       0  2.514070e-01\n",
       "3563        0       1  9.763748e-01\n",
       "7275        1       1  9.999994e-01\n",
       "6654        1       0  5.853920e-03\n",
       "7481        0       1  7.451806e-01\n",
       "6030        1       0  7.031754e-08\n",
       "10938       1       1  8.801218e-01\n",
       "5493        0       0  4.917133e-13\n",
       "5456        0       0  5.904980e-09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>p_homewin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999204e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.998911e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.437917e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999973e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.769963e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999949e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.479797e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999979e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999737e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999284e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_true  y_pred     p_homewin\n",
       "291        0       1  9.999204e-01\n",
       "2736       1       1  9.998911e-01\n",
       "2334       1       0  1.437917e-07\n",
       "432        1       1  9.999973e-01\n",
       "479        0       1  9.769963e-01\n",
       "1128       0       1  9.999949e-01\n",
       "501        0       0  4.479797e-02\n",
       "3105       1       1  9.999979e-01\n",
       "2779       1       1  9.999737e-01\n",
       "2099       0       1  9.999284e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>p_homewin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_true  y_pred  p_homewin\n",
       "718        1       1   0.996195\n",
       "3116       0       1   0.575532\n",
       "3061       0       1   0.999521\n",
       "2552       0       1   0.999418\n",
       "120        0       1   0.999866\n",
       "3578       0       1   0.999570\n",
       "2453       0       0   0.379209\n",
       "3983       1       1   0.981803\n",
       "3848       1       1   0.985323\n",
       "561        0       0   0.314340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample_preds(model, X, y, split_name, n=10):\n",
    "    Xd = to_dense(X)\n",
    "    yhat = model.predict(Xd)\n",
    "    try:\n",
    "        p1 = model.predict_proba(Xd)[:,1]\n",
    "    except Exception:\n",
    "        p1 = np.full_like(yhat, fill_value=np.nan, dtype='float64')\n",
    "    out = pd.DataFrame({\"y_true\": y, \"y_pred\": yhat, \"p_homewin\": p1})\n",
    "    print(f\"\\n{split_name} sample predictions:\")\n",
    "    display(out.sample(min(n, len(out)), random_state=42))\n",
    "\n",
    "sample_preds(best_model, X_tr, y_tr, \"TRAIN\")\n",
    "sample_preds(best_model, X_va, y_va, \"VALIDATION\")\n",
    "sample_preds(best_model, X_te, y_te, \"TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Diagnosis & Next Steps\n",
    "### Place the model on the biasâ€“variance curve; propose improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>gap</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>Near sweet-spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.039</td>\n",
       "      <td>Near sweet-spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.025</td>\n",
       "      <td>Near sweet-spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.096</td>\n",
       "      <td>Overfitting (high variance)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  train_acc  val_acc    gap                    diagnosis\n",
       "0    NaiveBayes      0.588    0.595 -0.007              Near sweet-spot\n",
       "1       SVM_RBF      0.623    0.584  0.039              Near sweet-spot\n",
       "2  DecisionTree      0.605    0.581  0.025              Near sweet-spot\n",
       "3           KNN      0.642    0.546  0.096  Overfitting (high variance)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: NaiveBayes\n",
      "Train acc=0.588  Val acc=0.595  Gap=-0.007\n",
      "Diagnosis: Near sweet-spot\n",
      "\n",
      "Next steps:\n",
      "- Small hyperparam polish (narrow grid around current best).\n",
      "- Feature enrichment: last-7/10/15 win%, rolling runs scored/allowed, opponent-adjusted stats.\n",
      "- Compare RandomForest vs tuned SVM; keep temporal CV.\n"
     ]
    }
   ],
   "source": [
    "def fit_position(train_acc, val_acc, baseline, gap_thresh=0.08, lift=0.03):\n",
    "    gap = train_acc - val_acc\n",
    "    if val_acc < baseline + lift and train_acc < baseline + lift:\n",
    "        return \"Underfitting (high bias)\"\n",
    "    if gap > gap_thresh and train_acc >= baseline + lift:\n",
    "        return \"Overfitting (high variance)\"\n",
    "    return \"Near sweet-spot\"\n",
    "\n",
    "def next_steps_for(model_name, diagnosis):\n",
    "    if \"Underfitting\" in diagnosis:\n",
    "        return (\n",
    "            \"- Increase capacity: SVM (RBF) with larger C, DecisionTree deeper (with pruning), or KNN with smaller k.\\n\"\n",
    "            \"- Add features: rolling form (last-7/10/15), opponent-adjusted z-scores, more matchup ratios/deltas.\\n\"\n",
    "            \"- Try RandomForest (bagging trees) to gain capacity without brittle splits.\"\n",
    "        )\n",
    "    if \"Overfitting\" in diagnosis:\n",
    "        return (\n",
    "            \"- Regularize: for SVM lower C; for DT prune (max_depth, min_samples_leaf, ccp_alpha).\\n\"\n",
    "            \"- Bagging with RandomForest to reduce variance; keep trees shallow-ish.\\n\"\n",
    "            \"- Reduce noisy features or cap poly interactions; use stronger CV.\"\n",
    "        )\n",
    "    return (\n",
    "        \"- Small hyperparam polish (narrow grid around current best).\\n\"\n",
    "        \"- Feature enrichment: last-7/10/15 win%, rolling runs scored/allowed, opponent-adjusted stats.\\n\"\n",
    "        \"- Compare RandomForest vs tuned SVM; keep temporal CV.\"\n",
    "    )\n",
    "\n",
    "baseline = max(np.mean(y_tr == 0), np.mean(y_tr == 1))\n",
    "\n",
    "diag_rows = []\n",
    "for _, r in summary.iterrows():\n",
    "    diagnosis = fit_position(r['train_acc'], r['val_acc'], baseline)\n",
    "    diag_rows.append({\n",
    "        'model': r['model'],\n",
    "        'train_acc': round(r['train_acc'], 3),\n",
    "        'val_acc': round(r['val_acc'], 3),\n",
    "        'gap': round(r['train_acc'] - r['val_acc'], 3),\n",
    "        'diagnosis': diagnosis\n",
    "    })\n",
    "diag_df = pd.DataFrame(diag_rows).sort_values(['val_acc','train_acc'], ascending=False)\n",
    "display(diag_df.head(6))\n",
    "\n",
    "best = diag_df.iloc[0]\n",
    "print(f\"Best model: {best['model']}\")\n",
    "print(f\"Train acc={best['train_acc']:.3f}  Val acc={best['val_acc']:.3f}  Gap={best['gap']:.3f}\")\n",
    "print(\"Diagnosis:\", best['diagnosis'])\n",
    "print(\"\\nNext steps:\\n\" + next_steps_for(best['model'], best['diagnosis']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5884040909425355\n",
      "Test  accuracy: 0.5798022598870056\n",
      "\n",
      "Confusion matrix (test):\n",
      " [[ 957 1111]\n",
      " [ 674 1506]]\n",
      "\n",
      "Classification report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.587     0.463     0.517      2068\n",
      "           1      0.575     0.691     0.628      2180\n",
      "\n",
      "    accuracy                          0.580      4248\n",
      "   macro avg      0.581     0.577     0.573      4248\n",
      "weighted avg      0.581     0.580     0.574      4248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_tr_pred = best_model.predict(X_tr_d)\n",
    "y_te_pred = best_model.predict(X_te_d)\n",
    "\n",
    "print(\"Train accuracy:\", accuracy_score(y_tr, y_tr_pred))\n",
    "print(\"Test  accuracy:\", accuracy_score(y_te, y_te_pred))\n",
    "print(\"\\nConfusion matrix (test):\\n\", confusion_matrix(y_te, y_te_pred))\n",
    "print(\"\\nClassification report (test):\\n\", classification_report(y_te, y_te_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of First Model\n",
    "\n",
    "#### Summarize performance and concrete improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained multiple allowed models (Decision Tree, KNN, SVM (RBF), Naive Bayes) on leakage-safe, engineered features and selected the best model by validation accuracy to avoid test peeking. The chosen model shows consistent generalization (train vs. validation close), indicating it is not severely overfitting. Test results are in line with validation, suggesting our preprocessing and temporal split are sound.\n",
    "\n",
    "#### Improvement:\n",
    "- Richer features: opponent-adjusted stats (z-scores vs league), rolling runs scored/allowed, separate last-7/10/15 windows, and home/away form asymmetry.\n",
    "\n",
    "-  Modeling: compare RandomForest (variance reduction over a single tree) vs a tuned SVM (RBF); keep selection on validation only.\n",
    "\n",
    "-  Regularization & tuning: for trees (max_depth, min_samples_leaf, ccp_alpha); for SVM (C, gamma).\n",
    "\n",
    "-  Calibration & thresholding: probability calibration (Platt/Isotonic) and decision thresholds if class costs differ.\n",
    "\n",
    "- Temporal CV: use walk-forward/blocked CV on the training period for more robust hyperparameter selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
